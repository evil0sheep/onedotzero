---
- name: Construct RPC endpoints string
  ansible.builtin.set_fact:
    llama_server_rpc_endpoints: >-
      {% set endpoints = [] %}
      {% for item in compute_nodes %}
      {%   set _ = endpoints.append(item.ip ~ ':' ~ llama_cpp_rpc_port) %}
      {% endfor %}
      {{ endpoints | join(',') }}

- name: Install build deps
  ansible.builtin.apt:
    name:
      - cmake
      - libcurl4-openssl-dev
      - pipx
    state: present
    update_cache: true

- name: Install huggingface_hub
  ansible.builtin.command:
    cmd: pipx install "huggingface_hub[cli]"
  changed_when: false

- name: Ensure pipx path
  ansible.builtin.command:
    cmd: pipx ensurepath
  changed_when: false

- name: Clone source
  ansible.builtin.git:
    repo: "https://github.com/ggml-org/llama.cpp.git"
    dest: "{{ llama_cpp_source_dir }}"
    version: "{{ llama_cpp_git_hash }}"
    force: true
    update: false

- name: Create a directory
  ansible.builtin.file:
    path: "{{ llama_cpp_build_dir }}"
    state: directory
    mode: "0755"

- name: CMake Configure
  ansible.builtin.command:
    cmd: cmake -S .. -DGGML_RPC=ON -DCMAKE_BUILD_TYPE=Release
    chdir: "{{ llama_cpp_build_dir }}"
  changed_when: false # CMake handles idempotence internally, always want to run

- name: CMake Build
  ansible.builtin.command:
    cmd: cmake --build . --config Release -- -j 16
    chdir: "{{ llama_cpp_build_dir }}"
  changed_when: false # CMake handles idempotence internally, always want to run

- name: Create model directory
  ansible.builtin.file:
    path: "{{ llama_cpp_models_dir }}"
    state: directory
    mode: "0755"
    owner: root
    group: root

- name: Download models
  ansible.builtin.command:
    cmd: >-
      /root/.local/bin/huggingface-cli download
      "{{ item['hf-repo'] }}"
      "{{ item['hf-file'] }}"
      --local-dir "{{ llama_cpp_models_dir }}"
      --local-dir-use-symlinks False
    creates: "{{ llama_cpp_models_dir }}/{{ item['hf-file'] }}"
  loop: "{{ llama_cpp_models }}"
  loop_control:
    label: "{{ item['hf-file'] }}"

- name: Create systemd unit file for llama.cpp server
  ansible.builtin.template:
    src: llama-server.service.j2
    dest: /etc/systemd/system/llama-server.service
    owner: root
    group: root
    mode: "0644"
  notify: Restart llama-server

- name: Ensure llama.cpp server is started and enabled on boot
  ansible.builtin.systemd:
    name: llama-server
    state: started
    enabled: true
    daemon_reload: true
